{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow: gradient descent y tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled compatitility to tf1.x\n"
     ]
    }
   ],
   "source": [
    "if tf.__version__.startswith(\"2.\"):\n",
    "  import tensorflow.compat.v1 as tf\n",
    "  tf.compat.v1.disable_v2_behavior()\n",
    "  tf.compat.v1.disable_eager_execution()\n",
    "  print(\"Enabled compatitility to tf1.x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('proyecto_training_data.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "segmentacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>FstFlrSF</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>LotFrontage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>180921.195890</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>1162.626712</td>\n",
       "      <td>6.517808</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>57.623288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>79442.502883</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>386.587738</td>\n",
       "      <td>1.625393</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>34.664304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>34900.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>129975.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>163000.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>214000.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1391.250000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>755000.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4692.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>313.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SalePrice  OverallQual     FstFlrSF  TotRmsAbvGrd    YearBuilt  \\\n",
       "count    1460.000000  1460.000000  1460.000000   1460.000000  1460.000000   \n",
       "mean   180921.195890     6.099315  1162.626712      6.517808  1971.267808   \n",
       "std     79442.502883     1.382997   386.587738      1.625393    30.202904   \n",
       "min     34900.000000     1.000000   334.000000      2.000000  1872.000000   \n",
       "25%    129975.000000     5.000000   882.000000      5.000000  1954.000000   \n",
       "50%    163000.000000     6.000000  1087.000000      6.000000  1973.000000   \n",
       "75%    214000.000000     7.000000  1391.250000      7.000000  2000.000000   \n",
       "max    755000.000000    10.000000  4692.000000     14.000000  2010.000000   \n",
       "\n",
       "       LotFrontage  \n",
       "count  1460.000000  \n",
       "mean     57.623288  \n",
       "std      34.664304  \n",
       "min       0.000000  \n",
       "25%      42.000000  \n",
       "50%      63.000000  \n",
       "75%      79.000000  \n",
       "max     313.000000  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largo = len(data)\n",
    "cols = ['SalePrice','OverallQual','FstFlrSF','TotRmsAbvGrd','YearBuilt','LotFrontage']\n",
    "\n",
    "tlargo = int(largo *1)\n",
    "datatrain = np.nan_to_num(data[:tlargo])\n",
    "\n",
    "dt = pd.DataFrame(datatrain,columns=cols)\n",
    "dt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularizacion de los datos\n",
    "\n",
    "No es esta utlizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_reg = dt[cols[1]]/120\n",
    "y_reg = dt[cols[0]] /100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase con el calculo del gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Objeto del modelo\n",
    "class GradientDesend:\n",
    "    def __init__(self,b0=0.,b1=0.):\n",
    "        tf.reset_default_graph()\n",
    "        self.b0 = tf.get_variable(\"B0\",dtype=tf.float32,\n",
    "                                  shape=[],initializer=tf.constant_initializer(b0))\n",
    "        self.b1 = tf.get_variable(\"B1\",dtype=tf.float32,\n",
    "                                  shape=[],initializer=tf.constant_initializer(b1))\n",
    "        self.error = tf.get_variable(\"error\",dtype=tf.float32,\n",
    "                                  shape=[],initializer=tf.zeros_initializer())\n",
    "        \n",
    "    def step(self,x,y,lr):\n",
    "        # hipotesis\n",
    "        yhat = tf.matmul(x,[[self.b0],[self.b1]],name=\"yhat\") \n",
    "\n",
    "        error = tf.reduce_mean(tf.math.square(y - yhat) ,name=\"reduce_mean\")/2\n",
    "\n",
    "        grad = tf.gradients(error,[self.b0,self.b1], name = \"gradients\")\n",
    "        \n",
    "        \n",
    "        local_b0 = tf.assign(self.b0, self.b0 - lr*grad[0] , name=\"assign_b0\")\n",
    "        local_b1 = tf.assign(self.b1, self.b1 - lr*grad[1] , name=\"assign_b1\")\n",
    "        local_error = tf.assign(self.error, error , name=\"assign_error\")\n",
    "        \n",
    "        \n",
    "        salida = tf.group(local_b0,local_b1,local_error, name=\"grupo\")\n",
    "\n",
    "        return salida\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nc = np.ones_like(dt[cols[1]])\n",
    "#x = np.hstack((np.expand_dims(dt[cols[1]],1),np.expand_dims(nc,1))) \n",
    "#x = dt[cols[1]]\n",
    "#print(x)\n",
    "#print(dt[cols[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "------ 0\n",
      "54616.324 10753.025 19184670000.0\n",
      "------ 1\n",
      "-298.55078 2605.333 19281152000.0\n",
      "------ 2\n",
      "54665.51 11612.168 19378117000.0\n",
      "------ 3\n",
      "-607.6758 3406.5068 19475845000.0\n",
      "------ 4\n",
      "54716.633 12467.561 19574290000.0\n",
      "------ 5\n",
      "-917.39844 4203.533 19673426000.0\n",
      "------ 6\n",
      "54769.54 13319.188 19773243000.0\n",
      "------ 7\n",
      "-1227.6172 4996.454 19873740000.0\n",
      "------ 8\n",
      "54824.13 14167.074 19974881000.0\n",
      "------ 9\n",
      "-1538.3594 5785.2783 20076712000.0\n",
      "------ 10\n",
      "54880.652 15011.208 20179261000.0\n",
      "------ 11\n",
      "-1849.8867 6569.998 20282650000.0\n",
      "------ 12\n",
      "54938.938 15851.707 20386700000.0\n",
      "------ 13\n",
      "-2161.871 7350.6953 20491393000.0\n",
      "------ 14\n",
      "54999.156 16688.543 20596838000.0\n",
      "------ 15\n",
      "-2474.6445 8127.3184 20703169000.0\n",
      "------ 16\n",
      "55061.125 17521.71 20810109000.0\n",
      "------ 17\n",
      "-2787.9375 8899.927 20917799000.0\n",
      "------ 18\n",
      "55124.99 18351.227 21026193000.0\n",
      "------ 19\n",
      "-3102.0 9668.49 21135473000.0\n",
      "------ 20\n",
      "55190.676 19177.117 21245436000.0\n",
      "------ 21\n",
      "-3416.6484 10433.056 21356147000.0\n",
      "------ 22\n",
      "55258.13 19999.398 21467630000.0\n",
      "------ 23\n",
      "-3731.7852 11193.672 21579776000.0\n",
      "------ 24\n",
      "55327.33 20818.129 21692680000.0\n"
     ]
    }
   ],
   "source": [
    "#plt.scatter(dt[cols[1]],dt[cols[0]])\n",
    "tf.reset_default_graph()\n",
    "init_b0 = 10\n",
    "init_b1 = 1800\n",
    "gd = GradientDesend(init_b0,init_b1)\n",
    "\n",
    "lr = 0.05\n",
    "iteracciones = 25\n",
    "\n",
    "dat_x = tf.placeholder(tf.float32,[tlargo,2],\"Value_x\")\n",
    "dat_y = tf.placeholder(tf.float32,[tlargo],\"Value_y\")\n",
    "\n",
    "#prediccion = gd.calculate(dat_x)\n",
    "step = gd.step(dat_x,dat_y,lr)\n",
    "\n",
    "\n",
    "nc = np.ones_like(dt[cols[1]])\n",
    "x = np.hstack((np.expand_dims(dt[cols[1]],1),np.expand_dims(nc,1))) \n",
    "#print(dat_x.shape)\n",
    "\n",
    "#print(x.shape)\n",
    "#print(dt[cols[0]].shape)\n",
    "error_summary = tf.summary.scalar('error', gd.error)\n",
    "\n",
    "with tf.train.MonitoredSession() as session:\n",
    "    localdir = \"logs/gradient_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"_lr=\" + str(lr) + \"_b0=\"+ str(init_b0) + \"_b1=\"+ str(init_b1)\n",
    "    #print(localdir)\n",
    "    feed_dict = {dat_x:x, dat_y:dt[cols[0]]}\n",
    "    writer = tf.summary.FileWriter(localdir , session.graph)\n",
    "    for i in range(iteracciones):\n",
    "        print('------',i)\n",
    "        \n",
    "        local_med = session.run(step,feed_dict=feed_dict)\n",
    "        #predicciones = session.run(prediccion,feed_dict=feed_dict)\n",
    "        cb0,cb1,cerror = session.run([gd.b0,gd.b1,gd.error],feed_dict=feed_dict)\n",
    "        summary = session.run(error_summary,feed_dict=feed_dict)\n",
    "        print(cb0,cb1,cerror)\n",
    "        #print(predicciones)\n",
    "        #print(local_med)\n",
    "        writer.add_summary(summary, i)\n",
    "        # plt.plot(x,predicciones,label=str(i))\n",
    "\n",
    "    \n",
    "    \n",
    "    # b0,b1,error = session.run([gd.b0,gd.b1,gd.error],feed_dict=feed_dict)\n",
    "    #getattr(gd, \"b1\")\n",
    "    #print(b0)\n",
    "    #writer.add_summary(error, )\n",
    "    \n",
    "    #plt.title(\"Par√°metros finales: m={}  b={} e={}\".format(b0,b1,error))\n",
    "\n",
    "#plt.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/gradient_20200519-215947_'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localdir = \"logs/gradient_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"_\"\n",
    "localdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## min 33:34\n",
    "salida = tf.summary.scalar(\"cost\",cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('./logs/gradient_2020' + str(1), session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 4.0]\n"
     ]
    }
   ],
   "source": [
    "# definir el grafo\n",
    "tf.reset_default_graph()\n",
    "a = tf.constant(1.0)\n",
    "b = tf.constant(1.0)\n",
    "c = tf.constant(4.0)\n",
    "d = tf.div(tf.add(a,b),c)\n",
    "\n",
    "\n",
    "# executar el grafo\n",
    "with tf.Session() as session:\n",
    "    writer = tf.summary.FileWriter('./logs', session.graph)\n",
    "    print(session.run([d,c])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# definir el grafo\n",
    "a = tf.constant(1.0)\n",
    "b = tf.constant(1.0)\n",
    "c = tf.constant(4.0)\n",
    "d = tf.add(tf.add(a,b),c)\n",
    "\n",
    "# executar el grafo\n",
    "with tf.Session() as session:\n",
    "  print(session.run(d)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with writing the scalar summary\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()   # To clear the defined variables and operations of the previous cell\n",
    "\n",
    "# create the scalar variable\n",
    "x_scalar = tf.get_variable('x_scalar', shape=[], initializer=tf.truncated_normal_initializer(mean=0, stddev=1))\n",
    "\n",
    "# ____step 1:____ create the scalar summary\n",
    "first_summary = tf.summary.scalar('My_first_scalar_summary', x_scalar)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # ____step 2:____ creating the writer inside the session\n",
    "    writer = tf.summary.FileWriter('./logs/test', sess.graph)\n",
    "    for step in range(100):\n",
    "        # loop over several initializations of the variable\n",
    "        sess.run(init)\n",
    "        # ____step 3:____ evaluate the scalar summary\n",
    "        summary = sess.run(first_summary)\n",
    "        # ____step 4:____ add the summary to the writer (i.e. to the event file)\n",
    "        writer.add_summary(summary, step)\n",
    "    print('Done with writing the scalar summary')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'nombre:0' shape=(2, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "v = tf.get_variable(name=\"nombre\",dtype=tf.float32,shape=[2,1], \n",
    "                    initializer=tf.random_normal_initializer(mean=0.0,stddev=0.5))\n",
    "\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul:0\", shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "datos = tf.constant([[2.0,1.0],\n",
    "                     [5.0,1.0]])\n",
    "y = tf.matmul(datos,v)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "derivada: [-8.0]\n"
     ]
    }
   ],
   "source": [
    "x_eval = -4\n",
    "def f(x):\n",
    "  return tf.math.square(x)\n",
    "\n",
    "x = tf.placeholder(tf.float32,[])\n",
    "y = f(x)\n",
    "\n",
    "derivada = tf.gradients(f(x),[x])\n",
    "\n",
    "with tf.train.MonitoredSession() as session:\n",
    "  feed_dict = {x:x_eval}\n",
    "\n",
    "  valor_y,valor_derivada = session.run([y,derivada],feed_dict)\n",
    "  print(\"derivada:\",valor_derivada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(3, 2), dtype=float32)\n",
      "<tf.Variable 'w:0' shape=(2, 1) dtype=float32_ref>\n",
      "[[ 5.]\n",
      " [11.]\n",
      " [ 7.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "#localw = tf.get_variable(name=\"w\",dtype=tf.float32,shape=[2,1],\n",
    "#                    initializer=tf.random_normal_initializer(mean=0.0,stddev=0.5))\n",
    "localw = tf.get_variable(name=\"w\",dtype=tf.float32,#shape=[2,1],\n",
    "                    initializer=tf.constant([[2.0],[1.0]]))\n",
    "\n",
    "datos = tf.constant([[2.0,1.0],\n",
    "                        [5.0,1.0],\n",
    "                        [3,1]])\n",
    "print(datos)\n",
    "print(localw)\n",
    "y = tf.matmul(datos,localw)\n",
    "#with tf.train.MonitoredSession() as session:\n",
    "#  print(session.run(y))\n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "with tf.Session() as session:\n",
    "  session.run(init)\n",
    "  print(session.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7. 1.]\n",
      " [6. 1.]\n",
      " [7. 1.]\n",
      " [7. 1.]\n",
      " [8. 1.]\n",
      " [5. 1.]\n",
      " [8. 1.]\n",
      " [7. 1.]\n",
      " [7. 1.]\n",
      " [5. 1.]\n",
      " [5. 1.]\n",
      " [9. 1.]\n",
      " [5. 1.]\n",
      " [7. 1.]]\n",
      "0     208500.0\n",
      "1     181500.0\n",
      "2     223500.0\n",
      "3     140000.0\n",
      "4     250000.0\n",
      "5     143000.0\n",
      "6     307000.0\n",
      "7     200000.0\n",
      "8     129900.0\n",
      "9     118000.0\n",
      "10    129500.0\n",
      "11    345000.0\n",
      "12    144000.0\n",
      "13    279500.0\n",
      "Name: SalePrice, dtype: float64\n",
      "Tensor(\"Value_x_5:0\", shape=(14, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "nc = np.ones_like(dt[cols[1]])\n",
    "x = np.hstack((np.expand_dims(dt[cols[1]],1),np.expand_dims(nc,1))) \n",
    "#x = dt[cols[1]]\n",
    "print(x)\n",
    "print(dt[cols[0]])\n",
    "\n",
    "dat_x = tf.placeholder(tf.float32,[tlargo,2],\"Value_x\")\n",
    "dat_y = tf.placeholder(tf.float32,[tlargo,2],\"Value_y\")\n",
    "\n",
    "print(dat_x)\n",
    "#prediccion = gd.calculate(dat_x)\n",
    "#modelo = gd.step(dat_x,dat_y,lr)\n",
    "\n",
    "\n",
    "#nc = np.ones_like(dt[cols[1]])\n",
    "#x = np.hstack((np.expand_dims(dt[cols[1]],1),np.expand_dims(nc,1))) \n",
    "#print(dat_x.shape)\n",
    "\n",
    "#print(x.shape)\n",
    "#print(dt[cols[0]].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
